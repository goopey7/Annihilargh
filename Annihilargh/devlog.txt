Wednesday (2/3/21)
After watching quite a few C++ and WINAPI tutorials. I finally decided to start writing some code in class today.
I have learned/watched videos that should cover pretty much everything I need to implement before getting into DirectX.
I have also learned of some things that DirectX does use such as COM objects and how to use interfaces with them.

Anyways, did a ton of stuff today. I created a really cool wrapper class for creating Windows which nicely encapsulates
all of the nasty WINAPI stuff. I also have implemented a very verbose way to throw exceptions using the WINAPI 
and I have implemented some error checking in my code. I'm not going to error check the stuff that happens before the 
creation of a window because I've never had it fail, and it would be too much time and effort.

Tomorrow or Friday I plan to create a Keyboard class which will act as an interface between the Window class and the 
game engine. The message handler in the Window class deals with input, so we need to give that to the keyboard and
then the game will get key events from the keyboard. Nice encapsulation away from the WINAPI.

Friday (2/5/21)
Today I created the keyboard class which acts as an interface between the Window class and the rest of the engine.
Next we have to deal with the mouse.

Saturday (2/6/21)
Got a nice mouse class similar to the keyboard class. Also got mouse capturing working. So, if the user drags off 
the client region and doesn't release a mouse button, move events still occur until the mouse buttons are released.
Also dealt with wheel delta. So now all mice are treated equally. So one mouse doesn't scroll faster or slower
than the other.

Tuesday (2/9/21)
Added a class to deal with game logic.
Also, moved the message processing in Annihilargh.cpp over to the Window class

// Yeah I know this isn't grammatically correct but it gets the info across.
Currently learning a bit about COM (Component Object Model) which DirectX utilizes.
Fortunately Direct3D will do a lot of this for me, so I don't have to become an expert in COM.
Basically COM gives us binary compatibility. Provides us a nice stable interface.
COM is language agnostic. It gives compatibility between different programming languages as well since
it is binary. Has it's own way of resource allocation since it is language independent.
Every COM object has a unique ID. COM objects are interacted with using an interface.
So if the way COM objects work or get created ever get changed via an update or something. The code will still work
thanks to the interface. COM uses reference counting, so we never explicitly have to delete it. Instead we call
Release which will decrement the reference count. We don't use 'new' either since that is language specific.
We use some kind of function to create a COM object. You call AddRef when you want to add something that works with
a COM object. QueryInterface takes a uuid (Universal Unique Identifier) of a COM object and a ptr to a ptr of the 
desired interface. It then checks to see if the COM object actually supports the interface provided, and
if it does, fills the ptr with a ptr to the queried interface. If QueryInterface is successful it will also
increase the reference count on the COM object since there is now another interface pointing to it.

Ok now I'm going to try and explain a bit about the Direct3D architecture.
We start with the Device which represents the graphics card/adapter.
The Device object is used to create all the other objects.

A SwapChain contains two frame buffers. The front buffer only contains a finished frame, and is what gets sent to the
screen. The back buffer is what we draw onto. We then swap the front and back buffers and repeat the process.
The reason we do this is because it would look awful if the monitor was reading row by row of our frame buffer while
we are also drawing onto it at the same time. What if we aren't done drawing an object that the screen has already read?
That's why we use this double buffer system.

However, screen tearing is still a possible issue. If the framebuffers swap while the monitor is in the middle of 
reading a frame buffer, there will be a tear in the screen (not literally). So we must make sure we only swap buffers
once the screen is done drawing. That's what Vsync is.

Device is used for allocating resources and creating objects. The Device Context is used for actually drawing and 
issuing rendering commands. 

Sunday (2/14/21)
Implemented Error handling for graphics w/directx functions
Also changed all dumb COM ptrs to smart COM ptrs.

Drew first triangle using the Direct3D pipeline. Currently very sloppy and inefficient since we are having to allocate
everything in the pipeline every draw call, but the entire pipeline is easy to see in one function.

Tuesday (2/16/21)
Now that I have a quick and dirty triangle drawing function, I am going to mess around with the pipeline.
See what I can do, and I'll probably also break stuff.

Adding triangles is as simple as just adding three more vertices to the list of vertices.
One thing I have found is that triangles are not displayed if the vertices wind counter clockwise.
Meaning we have to draw vertices in a clockwise manner. (top then right then left)

If I want to draw lines instead of triangles, all I have to do is change the primitive topology.
pDeviceContext->IASetPrimitiveTopology(D3D11_PRIMITIVE_TOPOLOGY_LINELIST);
Obviously lines are different from triangles. They require two vertices not three. But nothing bad
happens if the amount of vertices is not a multiple of two.

I have assigned each vertex of the triangle a different colour. The rasterizer blends them together in a cool way.

Friday (2/19/21)
Implemented indexed drawing. This allows us to compress the vertex buffer because we don't have to fill the buffer
with duplicate vertices. Instead, we have an index buffer that indexes into the vertex buffer so we can reuse the same
vertex without duplicating it in the vertex buffer!
This reduces the amount of vertex data that is sent to the graphics adapter, and also gives the chance for the graphics
adapter to fetch a recently used vertex from its vertex cache which is better for performance.

Monday (2/22/21)
Unfortunately I did not work on this over the weekend. I left my literature review for senior plan for that weekend,
so I mainly did that. I also have no free periods. Meaning I am in 9 classes including senior plan.

Anyways, had a big session today. Today I accomplished drawing a 3D cube that rotates. I also managed to colour in all
the sides an individual colour. Each side is made up of two triangles. The triangles are drawn using indexed drawing.
So we have a vertex buffer containing the vertices, and an index buffer defining how the vertices are connected, so
the actual triangles that are drawn. To actually colour the faces, I setup a constant buffer containing 6 colours,
one for each face, for the pixel shader. Then in the pixel shader you can get Direct3D to assign an index all the 
triangles, and then I used that index to select a colour from the constant buffer that was just bound to the shader.

Also added a z-buffer. This allows us to properly simulate depth. Before adding the z-buffer, objects would be drawn one
on top of the other just depending on the order they were drawn. So, we create a depth texture by comparing the z-value
of all vertices or maybe pixels hmmmmmm. Smaller z-values are closer to the screen, so they should be drawn last. That's
the idea, and it works now.

Tuesday (2/23/21)
Yesterday was a great success! But now it is time to do some design because right now the entire pipeline is in one 
function. All bindable elements of the pipeline and the buffers used to represent the cube, are created and destroyed
every frame. The function was great for learning about the pipeline, but now that I do understand how everything works,
it is time to refactor. This current function is definitely not going to work in the future because the framerate is
going to suffer a lot for no good reason if we spawn in a thousand cubes every frame. So, I want these buffers to
persist between frames.

So, here's what the design is going to look like so everything is nice, neat, and convenient:

Create a Bindable interface containing a Bind function that gets implemented by anything that needs to be bound to the 
pipeline. Such as our shaders, constant buffer etc. The Bind function will take in a Graphics object as a parameter.
So we will create classes for each bindable thing, and they will inherit from the bindable interface.

Also create a Drawable interface which can be implemented by things such as a Cube object. Drawable objects will contain
bindable objects. Definitely a vertex shader and a pixel shader for example. However, objects that implement Drawable
will have different sets of Bindable objects. So, what's nice about this is that these varying Bindables can just be
put into a std::vector using polymorphism. So Drawable supports any combination of Bindable objects.
Drawable will have an already implemented Draw function which takes in a Graphics object as a parameter.
This function is simply going to bind all bindables to the pipeline using the Bind function. Then it will
call Draw through the graphics object passed in. 

This design also provides persistence of bindables between frames since they are all going to be their own object.
So not only does the code look good, but it actually also performs better too.

Now I have to actually implement this ingenious design plan.

A few hours later... (doing other work and dinner)

(22:45) Let's start implementing this plan!

Wednesday (2/24/21)

(2:16AM) well I finally did it. spent 2-3 hrs debugging. I think I probably should have stopped earlier I'm definitely
too tired. I was copy/pasting from the DrawTestTriangle function in Graphics and so I missed a few things.
I really think I should probably go to bed. I think I have a calc BC quiz tomorrow lol. Well now I can spawn in 
loads of cubes with ease!!!

Saturday (2/27/21)
The Bindable/Drawable design works now, but it can still be improved. First thing I'd like to improve is the fact that
all 100 cubes being spawned use the exact same D3D elements, but each cube instance has their own instances of D3D 
elements. So, we're creating 100 vertex buffers, 100 pixel shaders etc.
That's pretty wasteful and so we want every drawable object to access a list of its common bindables shared with other
drawables of the same type.
We can get around that with the use of static variables. However, it would kind of suck if I had to copy/paste this for 
every type of drawable. Also, the Draw function is only aware of the per instance bindables in the vector, 
not static ones pertaining to a specific type of Drawable.
And I can't do it in the Drawable interface because that would create one static vector shared between
all types that inherit from Drawable. We don't want that. We want each Drawable type to have its own shared vector.
So for example all Cubes share a vector of Bindables and all spheres share a different vector of Bindables. 
Fortunately we can get the compiler to do the copy/pasting for us by creating a DrawableBase<T> class which is
templated. This class would sit in between the drawable types and the drawable interface.
So our cube would inherit from DrawableBase<Cube> and DrawableBase<T> inherits from Drawable.
That way the compiler will copy/paste the DrawableBase<T> class for every different template used. Meaning we get
different static vectors for different types. And we can just use the type of Drawable for the template because it 
works and it's intuitive.

So now that I have implemented that, the only Bindable that is not static for cubes is the TransformationConstantBuffer
because all the different cube instances are going to have different positions and rotations. However, the entire 
TransformationConstantBuffer doesn't need to be separate for each cube. All that really needs to happen to transform a
cube is to update a constant buffer and then bind it to the pipeline. And it turns out that we can reuse the same 
constant buffer for each cube and then each cube would have to update it with various transformations.
This is an easy fix. Just simply make a static ptr to a vertex constant buffer. That way the same vertex constant buffer
persists between different instances of TransformationConstantBuffer. So I have severely decreased the amount of
resources being duplicated for no reason, and I am noticing an increase in performance when running the program now.

To properly test to make sure this works I should definitely add other Drawables than just the Cube.

Monday (3/1/21)
Separated the Mathematical representation of a Cube from the Drawable Cube that binds to the pipeline.
I'm going to have some Geometric Primitives that can be created statically. Next I'm going to try and implement
a sphere which is gonna be difficult.

Well I got the sphere kind of working. But I can see that the triangles aren't being drawn correctly.
Geez that was a lot of math.
Anyways, I'm looking forward to loading 3D models so I can forget about 3D geometry :)
Ok, I fixed the indexes so now the triangles have disappeared and you see a sphere.
But the pixel shader was not colouring in all the triangles hmmmmmm.
Well after 30 minutes turns out my shaders were compiling to a different directory, meaning that the changes I made
to the pixel shader were not actually affecting my program at all. Lol. Now it all looks good. 

I also tested out how nice it would be to use this system in Game.cpp. It's beautiful. Just have a list of drawables
containing cubes and melons. Ahhhh beautiful.

Tuesday (3/2/21)
Time to start learning about how to implement textures in Direct3D!
Instead of using the helper functions in the DirectXTK. I'm gonna load the images using GDIPlus and then manually
get them into the Direct3D pipeline.

Got GDIPlus working. Now I need to get Textures in Direct3D working. You bind textures to the pipeline, but you also
need a sampler which specifies how the texture is going to be used. Is it going to be wrapped how will it be filtered?
Linear interpolation? Point sampling? Anisotropic? Depends on what the art style is.

Well I've done it. Fortunately for more complex meshes loaded from files, the texture coordinates are already done for
you.

Now I'm going to incorporate ImGui (https://github.com/ocornut/imgui) into the project. I'm not making my own GUI system
because life is too short.

Got imgui integrated into my code. Everything is looking pretty good.
Also can now control the camera using a camera class and we have a GUI for controlling the camera's location and 
rotation.

Sunday (3/14/21)
Yeah took a massive break whoops. Had a lot of things to do over the last week, and knowing that I can put in a lot of
hours over spring break put me off working on it last week. Now I have much more uninterrupted time to spend with this
project. So, today I'm going to try and implement some form of dynamic lighting.